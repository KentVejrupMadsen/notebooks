{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c80d7927ae084",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install ipympl -q\n",
    "%pip install numpy -q\n",
    "%pip install wheel\n",
    "\n",
    "%pip install keras -q\n",
    "%pip install keras-cv -q\n",
    "\n",
    "%pip install matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc7a0b0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T18:56:46.985860500Z",
     "start_time": "2024-01-23T18:56:46.984859900Z"
    }
   },
   "outputs": [],
   "source": [
    "location_to_saved_model: str = '/home/spectre/environment_model.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54f7a7880613789",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T18:56:50.593170800Z",
     "start_time": "2024-01-23T18:56:48.515313100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 19:56:48.820115: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-23 19:56:48.868285: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-23 19:56:48.868312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-23 19:56:48.869927: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-23 19:56:48.879624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-23 19:56:49.563894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-23 19:56:50.527021: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 19:56:50.582498: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-23 19:56:50.582536: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "gpus = tensorflow.config.list_physical_devices(\n",
    "    'GPU'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78efad1525675374",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T18:56:51.730686400Z",
     "start_time": "2024-01-23T18:56:51.727574500Z"
    }
   },
   "outputs": [],
   "source": [
    "nvidia_maximum_limit_for_gpu_memory: int = 5925\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tensorflow.config.set_logical_device_configuration(\n",
    "                gpu, \n",
    "                [\n",
    "                    tensorflow.config.LogicalDeviceConfiguration(\n",
    "                        memory_limit=nvidia_maximum_limit_for_gpu_memory\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "location_to_dataset: str = '/tmp/dataset'\n",
    "name_of_location: str = 'LocationDataset'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anubis\tDefault  Dust-II  Mirage  Vertigo\r\n"
     ]
    }
   ],
   "source": [
    "from os.path import isdir\n",
    "\n",
    "if not isdir(\n",
    "    location_to_dataset\n",
    "):\n",
    "    !git clone https://github.com/TargetSpectre/Location-Identification-DataSet.git {name_of_location} \n",
    "    !mv ./{name_of_location}/DataSet {location_to_dataset}\n",
    "\n",
    "!ls {location_to_dataset}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T18:56:54.664129600Z",
     "start_time": "2024-01-23T18:56:54.545221500Z"
    }
   },
   "id": "7dc6ed6a8900bce5",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "ed941738",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0d20fc90b41c40",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T18:31:51.689225600Z",
     "start_time": "2024-01-23T18:31:51.682514200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anubis', 'Default', 'Dust-II', 'Mirage', 'Vertigo']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "labels: list = list()\n",
    "found_dirs = listdir(\n",
    "    location_to_dataset\n",
    ")\n",
    "\n",
    "for idx in range(\n",
    "    len(\n",
    "        found_dirs\n",
    "    )\n",
    "):\n",
    "    selected = found_dirs[idx]\n",
    "    labels.append(\n",
    "        selected\n",
    "    )\n",
    "\n",
    "    found_dirs[idx] = join(\n",
    "        location_to_dataset, \n",
    "        selected\n",
    "    )\n",
    "\n",
    "labels.sort()\n",
    "\n",
    "print(\n",
    "    labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8106168a00a72e9f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T18:57:05.836214700Z",
     "start_time": "2024-01-23T18:57:05.831525700Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import SystemRandom\n",
    "from keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb75f414c9431633",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T20:32:59.147439300Z",
     "start_time": "2024-01-23T20:32:59.143181500Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size: int = 2\n",
    "buffer_size: int = 10\n",
    "\n",
    "number_of_training_iterations: int = 5  \n",
    "\n",
    "vision_width: int = 960\n",
    "vision_height: int = 540\n",
    "\n",
    "maximum_value: int = 65535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22c3fadb35bf6cec",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T20:33:02.155962400Z",
     "start_time": "2024-01-23T20:33:02.150765500Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"location_identifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 540, 960, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 540, 960, 4)       52        \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 540, 960, 4)       68        \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 540, 960, 4)       68        \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 540, 960, 4)       68        \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 540, 960, 4)       16        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 270, 480, 4)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 270, 480, 8)       136       \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 270, 480, 8)       264       \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 270, 480, 8)       264       \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 270, 480, 8)       264       \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 270, 480, 8)       32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 135, 240, 8)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 135, 240, 16)      528       \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 135, 240, 16)      1040      \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 135, 240, 16)      1040      \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 135, 240, 16)      1040      \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 135, 240, 16)      64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 68, 120, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 68, 120, 32)       2080      \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 68, 120, 32)       4128      \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 68, 120, 32)       4128      \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 68, 120, 32)       4128      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 68, 120, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 34, 60, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 34, 60, 64)        8256      \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 34, 60, 64)        16448     \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 34, 60, 64)        16448     \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 34, 60, 64)        16448     \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 34, 60, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 17, 30, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 17, 30, 96)        24672     \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 17, 30, 96)        36960     \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 17, 30, 96)        384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 9, 15, 96)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12960)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1024)              13272064  \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13938837 (53.17 MB)\n",
      "Trainable params: 13938397 (53.17 MB)\n",
      "Non-trainable params: 440 (1.72 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\n",
    "    location_to_saved_model\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer   = Adam(\n",
    "        learning_rate   = 0.001,\n",
    "        amsgrad         = True,\n",
    "        global_clipnorm = 10.0,\n",
    "        use_ema         = True\n",
    "    ),\n",
    "    loss        = 'categorical_crossentropy',\n",
    "    metrics     = ['accuracy']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T20:33:17.561528800Z",
     "start_time": "2024-01-23T20:33:06.051075700Z"
    }
   },
   "id": "a6da1a65466e5083",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.callbacks \\\n",
    "    import EarlyStopping\n",
    "\n",
    "callbacks: list = [\n",
    "    EarlyStopping(\n",
    "        monitor                 = 'accuracy',\n",
    "        min_delta               = 0,\n",
    "        patience                = 0,\n",
    "        mode                    = 'max',\n",
    "        restore_best_weights    = True,\n",
    "        start_from_epoch        = 2\n",
    "    )\n",
    "]\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T18:57:50.751382800Z",
     "start_time": "2024-01-23T18:57:50.741867700Z"
    }
   },
   "id": "ada6a993",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_random_int16_number() -> int:\n",
    "    global maximum_value\n",
    "    return SystemRandom().randint(\n",
    "            1, \n",
    "            maximum_value\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T20:13:51.715481200Z",
     "start_time": "2024-01-23T20:13:51.674041200Z"
    }
   },
   "id": "a0071aa0af10a0fb",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_training_dataset():\n",
    "    global batch_size, vision_height, vision_width\n",
    "    \n",
    "    return image_dataset_from_directory(\n",
    "        location_to_dataset,\n",
    "        labels                  = 'inferred',\n",
    "        label_mode              = 'categorical',\n",
    "        color_mode              = 'rgb',\n",
    "        batch_size              = batch_size,\n",
    "        image_size              = (\n",
    "            vision_height, \n",
    "            vision_width\n",
    "        ),\n",
    "        shuffle                 = True,\n",
    "        crop_to_aspect_ratio    = True,\n",
    "        subset                  = 'training',\n",
    "        validation_split        = 0.25,\n",
    "        seed                    = generate_random_int16_number()\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T20:14:10.423899700Z",
     "start_time": "2024-01-23T20:14:10.414846200Z"
    }
   },
   "id": "d1b2dce863098bfb",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_validation_dataset():\n",
    "    global batch_size, vision_height, vision_width\n",
    "    return image_dataset_from_directory(\n",
    "        location_to_dataset,\n",
    "        labels                  = 'inferred',\n",
    "        label_mode              = 'categorical',\n",
    "        color_mode              = 'rgb',\n",
    "        batch_size              = batch_size,\n",
    "        image_size              = (\n",
    "            vision_height, \n",
    "            vision_width\n",
    "        ),\n",
    "        shuffle                 = True,\n",
    "        crop_to_aspect_ratio    = True,\n",
    "        subset                  = 'validation',\n",
    "        validation_split        = 0.25,\n",
    "        seed                    = generate_random_int16_number()\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T20:14:12.399180400Z",
     "start_time": "2024-01-23T20:14:12.390550900Z"
    }
   },
   "id": "470e2e0727428602",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "number_of_epochs: int = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T20:14:15.985313500Z",
     "start_time": "2024-01-23T20:14:15.981660800Z"
    }
   },
   "id": "181fce7bd4225c7",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d260b8439fc7d23d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T20:33:56.827100Z",
     "start_time": "2024-01-23T20:33:56.816788700Z"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    global callbacks, number_of_epochs\n",
    "    \n",
    "    training_dataset = generate_training_dataset()\n",
    "    validation_dataset = generate_validation_dataset()\n",
    "\n",
    "    history = model.fit(\n",
    "        training_dataset.prefetch(\n",
    "            buffer_size = buffer_size\n",
    "        ), \n",
    "        epochs              = number_of_epochs, \n",
    "        validation_data     = validation_dataset.prefetch(\n",
    "                                buffer_size = buffer_size\n",
    "                              ),\n",
    "        workers             = 12,\n",
    "        callbacks           = callbacks,\n",
    "        verbose             = 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12300 files belonging to 5 classes.\n",
      "Using 9225 files for training.\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 3075 files for validation.\n",
      "Epoch 1/10\n",
      "4613/4613 - 222s - loss: 9.4888 - accuracy: 0.3456 - val_loss: 9.6813 - val_accuracy: 0.3580 - 222s/epoch - 48ms/step\n",
      "Epoch 2/10\n",
      "4613/4613 - 208s - loss: 9.4503 - accuracy: 0.3410 - val_loss: 9.6865 - val_accuracy: 0.3587 - 208s/epoch - 45ms/step\n",
      "Epoch 3/10\n",
      "4613/4613 - 210s - loss: 9.4608 - accuracy: 0.3457 - val_loss: 9.6760 - val_accuracy: 0.3584 - 210s/epoch - 45ms/step\n",
      "Epoch 4/10\n",
      "4613/4613 - 209s - loss: 9.4870 - accuracy: 0.3440 - val_loss: 9.6865 - val_accuracy: 0.3577 - 209s/epoch - 45ms/step\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 9225 files for training.\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 3075 files for validation.\n",
      "Epoch 1/10\n",
      "4613/4613 - 207s - loss: 9.4975 - accuracy: 0.3473 - val_loss: 9.7966 - val_accuracy: 0.3564 - 207s/epoch - 45ms/step\n",
      "Epoch 2/10\n",
      "4613/4613 - 207s - loss: 9.4975 - accuracy: 0.3451 - val_loss: 9.7861 - val_accuracy: 0.3558 - 207s/epoch - 45ms/step\n",
      "Epoch 3/10\n",
      "4613/4613 - 207s - loss: 9.5255 - accuracy: 0.3469 - val_loss: 9.8228 - val_accuracy: 0.3567 - 207s/epoch - 45ms/step\n",
      "Epoch 4/10\n",
      "4613/4613 - 207s - loss: 9.4993 - accuracy: 0.3450 - val_loss: 9.8123 - val_accuracy: 0.3567 - 207s/epoch - 45ms/step\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 9225 files for training.\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 3075 files for validation.\n",
      "Epoch 1/10\n",
      "4613/4613 - 206s - loss: 9.4888 - accuracy: 0.3396 - val_loss: 9.8385 - val_accuracy: 0.3613 - 206s/epoch - 45ms/step\n",
      "Epoch 2/10\n",
      "4613/4613 - 207s - loss: 9.4905 - accuracy: 0.3402 - val_loss: 9.8385 - val_accuracy: 0.3607 - 207s/epoch - 45ms/step\n",
      "Epoch 3/10\n",
      "4613/4613 - 206s - loss: 9.5167 - accuracy: 0.3447 - val_loss: 9.8438 - val_accuracy: 0.3607 - 206s/epoch - 45ms/step\n",
      "Epoch 4/10\n",
      "4613/4613 - 206s - loss: 9.4993 - accuracy: 0.3396 - val_loss: 9.8438 - val_accuracy: 0.3613 - 206s/epoch - 45ms/step\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 9225 files for training.\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 3075 files for validation.\n",
      "Epoch 1/10\n",
      "4613/4613 - 206s - loss: 9.4137 - accuracy: 0.3469 - val_loss: 9.6708 - val_accuracy: 0.3714 - 206s/epoch - 45ms/step\n",
      "Epoch 2/10\n",
      "4613/4613 - 212s - loss: 9.4713 - accuracy: 0.3457 - val_loss: 9.6970 - val_accuracy: 0.3714 - 212s/epoch - 46ms/step\n",
      "Epoch 3/10\n",
      "4613/4613 - 211s - loss: 9.4189 - accuracy: 0.3481 - val_loss: 9.6970 - val_accuracy: 0.3714 - 211s/epoch - 46ms/step\n",
      "Epoch 4/10\n",
      "4613/4613 - 213s - loss: 9.4276 - accuracy: 0.3489 - val_loss: 9.6813 - val_accuracy: 0.3714 - 213s/epoch - 46ms/step\n",
      "Epoch 5/10\n",
      "4613/4613 - 212s - loss: 9.3892 - accuracy: 0.3468 - val_loss: 9.6813 - val_accuracy: 0.3717 - 212s/epoch - 46ms/step\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 9225 files for training.\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 3075 files for validation.\n",
      "Epoch 1/10\n",
      "4613/4613 - 211s - loss: 9.4731 - accuracy: 0.3417 - val_loss: 9.5083 - val_accuracy: 0.3691 - 211s/epoch - 46ms/step\n",
      "Epoch 2/10\n",
      "4613/4613 - 213s - loss: 9.4800 - accuracy: 0.3398 - val_loss: 9.5083 - val_accuracy: 0.3694 - 213s/epoch - 46ms/step\n",
      "Epoch 3/10\n",
      "4613/4613 - 213s - loss: 9.5272 - accuracy: 0.3416 - val_loss: 9.5031 - val_accuracy: 0.3694 - 213s/epoch - 46ms/step\n",
      "Epoch 4/10\n",
      "4613/4613 - 210s - loss: 9.4870 - accuracy: 0.3419 - val_loss: 9.4978 - val_accuracy: 0.3698 - 210s/epoch - 46ms/step\n",
      "Epoch 5/10\n",
      "4613/4613 - 209s - loss: 9.4731 - accuracy: 0.3395 - val_loss: 9.5083 - val_accuracy: 0.3698 - 209s/epoch - 45ms/step\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 9225 files for training.\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 3075 files for validation.\n",
      "Epoch 1/10\n",
      "4613/4613 - 211s - loss: 9.5779 - accuracy: 0.3436 - val_loss: 9.8595 - val_accuracy: 0.3496 - 211s/epoch - 46ms/step\n",
      "Epoch 2/10\n",
      "4613/4613 - 211s - loss: 9.5464 - accuracy: 0.3395 - val_loss: 9.8700 - val_accuracy: 0.3493 - 211s/epoch - 46ms/step\n",
      "Epoch 3/10\n",
      "4613/4613 - 211s - loss: 9.5709 - accuracy: 0.3427 - val_loss: 9.8490 - val_accuracy: 0.3496 - 211s/epoch - 46ms/step\n",
      "Epoch 4/10\n",
      "4613/4613 - 210s - loss: 9.5919 - accuracy: 0.3397 - val_loss: 9.8542 - val_accuracy: 0.3496 - 210s/epoch - 45ms/step\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 9225 files for training.\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 3075 files for validation.\n",
      "Epoch 1/10\n",
      "4613/4613 - 208s - loss: 9.5429 - accuracy: 0.3421 - val_loss: 9.8280 - val_accuracy: 0.3519 - 208s/epoch - 45ms/step\n",
      "Epoch 2/10\n",
      "4613/4613 - 210s - loss: 9.5307 - accuracy: 0.3429 - val_loss: 9.8385 - val_accuracy: 0.3528 - 210s/epoch - 45ms/step\n",
      "Epoch 3/10\n",
      "4613/4613 - 211s - loss: 9.5028 - accuracy: 0.3410 - val_loss: 9.8176 - val_accuracy: 0.3519 - 211s/epoch - 46ms/step\n",
      "Epoch 4/10\n",
      "4613/4613 - 210s - loss: 9.5080 - accuracy: 0.3415 - val_loss: 9.8280 - val_accuracy: 0.3519 - 210s/epoch - 46ms/step\n",
      "Epoch 5/10\n",
      "4613/4613 - 212s - loss: 9.5097 - accuracy: 0.3430 - val_loss: 9.8385 - val_accuracy: 0.3522 - 212s/epoch - 46ms/step\n",
      "Epoch 6/10\n",
      "4613/4613 - 210s - loss: 9.5779 - accuracy: 0.3435 - val_loss: 9.8175 - val_accuracy: 0.3522 - 210s/epoch - 46ms/step\n",
      "Epoch 7/10\n",
      "4613/4613 - 204s - loss: 9.5132 - accuracy: 0.3414 - val_loss: 9.8385 - val_accuracy: 0.3522 - 204s/epoch - 44ms/step\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 9225 files for training.\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 3075 files for validation.\n",
      "Epoch 1/10\n",
      "4613/4613 - 207s - loss: 9.5290 - accuracy: 0.3446 - val_loss: 9.7704 - val_accuracy: 0.3678 - 207s/epoch - 45ms/step\n",
      "Epoch 2/10\n",
      "4613/4613 - 212s - loss: 9.5115 - accuracy: 0.3424 - val_loss: 9.7809 - val_accuracy: 0.3678 - 212s/epoch - 46ms/step\n",
      "Epoch 3/10\n",
      "4613/4613 - 211s - loss: 9.5464 - accuracy: 0.3422 - val_loss: 9.7861 - val_accuracy: 0.3685 - 211s/epoch - 46ms/step\n",
      "Epoch 4/10\n",
      "4613/4613 - 212s - loss: 9.5429 - accuracy: 0.3432 - val_loss: 9.7809 - val_accuracy: 0.3678 - 212s/epoch - 46ms/step\n",
      "Epoch 5/10\n",
      "4613/4613 - 213s - loss: 9.5045 - accuracy: 0.3458 - val_loss: 9.7704 - val_accuracy: 0.3675 - 213s/epoch - 46ms/step\n",
      "Epoch 6/10\n",
      "4613/4613 - 211s - loss: 9.5360 - accuracy: 0.3418 - val_loss: 9.7494 - val_accuracy: 0.3681 - 211s/epoch - 46ms/step\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 9225 files for training.\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 3075 files for validation.\n",
      "Epoch 1/10\n",
      "4613/4613 - 209s - loss: 9.5726 - accuracy: 0.3442 - val_loss: 9.8071 - val_accuracy: 0.3509 - 209s/epoch - 45ms/step\n",
      "Epoch 2/10\n",
      "4613/4613 - 213s - loss: 9.5290 - accuracy: 0.3433 - val_loss: 9.8228 - val_accuracy: 0.3519 - 213s/epoch - 46ms/step\n",
      "Epoch 3/10\n",
      "4613/4613 - 210s - loss: 9.5202 - accuracy: 0.3428 - val_loss: 9.8071 - val_accuracy: 0.3512 - 210s/epoch - 45ms/step\n",
      "Epoch 4/10\n",
      "4613/4613 - 208s - loss: 9.4975 - accuracy: 0.3428 - val_loss: 9.8176 - val_accuracy: 0.3519 - 208s/epoch - 45ms/step\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 9225 files for training.\n",
      "Found 12300 files belonging to 5 classes.\n",
      "Using 3075 files for validation.\n",
      "Epoch 1/10\n",
      "4613/4613 - 209s - loss: 9.4818 - accuracy: 0.3438 - val_loss: 9.6393 - val_accuracy: 0.3561 - 209s/epoch - 45ms/step\n",
      "Epoch 2/10\n",
      "4613/4613 - 208s - loss: 9.4521 - accuracy: 0.3434 - val_loss: 9.6393 - val_accuracy: 0.3561 - 208s/epoch - 45ms/step\n",
      "Epoch 3/10\n",
      "4613/4613 - 209s - loss: 9.4713 - accuracy: 0.3449 - val_loss: 9.6288 - val_accuracy: 0.3561 - 209s/epoch - 45ms/step\n",
      "Epoch 4/10\n",
      "4613/4613 - 209s - loss: 9.4888 - accuracy: 0.3431 - val_loss: 9.6341 - val_accuracy: 0.3561 - 209s/epoch - 45ms/step\n"
     ]
    }
   ],
   "source": [
    "for idx in range(\n",
    "    number_of_training_iterations\n",
    "):\n",
    "    train()\n",
    "\n",
    "model.save(\n",
    "    location_to_saved_model,\n",
    "    overwrite = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T23:18:33.886325700Z",
     "start_time": "2024-01-23T20:34:00.090292400Z"
    }
   },
   "id": "4911d8915d686eab",
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
